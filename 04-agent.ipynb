{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building AI Agent Bot With RAG, Langchain, and Reasoning Engine From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "from langchain.agents.format_scratchpad import format_to_openai_function_messages\n",
    "from langchain.agents import tool\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "from vertexai.preview import reasoning_engines\n",
    "from langchain_google_vertexai import HarmBlockThreshold, HarmCategory\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db connection: postgres://testing:testing@35.232.5.157:5432/testing\n",
      "api base url: https://courses-api-uzttxm4diq-uc.a.run.app\n"
     ]
    }
   ],
   "source": [
    "# constan definitions\n",
    "# USE_CLOUDSQL = False\n",
    "USE_CLOUDSQL = True\n",
    "\n",
    "project_id = \"imrenagi-gemini-experiment\" #change this to your project id\n",
    "region = \"us-central1\" #change this to project location\n",
    "gemini_embedding_model = \"text-embedding-004\"\n",
    "gemini_llm_model = \"gemini-1.5-pro-001\"\n",
    "staging_bucket_name = \"courses-imrenagicom-agent\"\n",
    "staging_bucket_uri = f\"gs://{staging_bucket_name}\"\n",
    "\n",
    "cloudrun_services = !gcloud run services describe courses-api --region=us-central1 --format='value(status.url)'\n",
    "api_base_url = cloudrun_services[0]\n",
    "# api_base_url = \"localhost:8080\"\n",
    "\n",
    "if not USE_CLOUDSQL:\n",
    "    # use pgvector docker image for local development\n",
    "    database_password = \"pyconapac\"\n",
    "    database_name = \"pyconapac\"\n",
    "    database_user = \"pyconapac\"\n",
    "    database_host = \"localhost\"\n",
    "else:\n",
    "    # use cloudsql credential if you want to use cloudsql\n",
    "    instance_name=\"pyconapac-demo\"\n",
    "    database_password = 'testing'\n",
    "    database_name = 'testing'\n",
    "    database_user = 'testing'\n",
    "\n",
    "\n",
    "assert database_name, \"⚠️ Please provide a database name\"\n",
    "assert database_user, \"⚠️ Please provide a database user\"\n",
    "assert database_password, \"⚠️ Please provide a database password\"\n",
    "\n",
    "if USE_CLOUDSQL:\n",
    "    # get the ip address of the cloudsql instance\n",
    "    ip_addresses = !gcloud sql instances describe {instance_name} --format=\"value(ipAddresses[0].ipAddress)\"\n",
    "    database_host = ip_addresses[0]\n",
    "\n",
    "db_conn_string = f\"postgres://{database_user}:{database_password}@{database_host}:5432/{database_name}\"\n",
    "\n",
    "print(f\"db connection: {db_conn_string}\")\n",
    "print(f\"api base url: {api_base_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "vertexai.init(project=project_id, location=region, staging_bucket=staging_bucket_uri)\n",
    "\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "embeddings_service = VertexAIEmbeddings(model_name=gemini_embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from typing import List\n",
    "\n",
    "# from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
    "# from langchain_core.documents import Document\n",
    "# from langchain_core.retrievers import BaseRetriever\n",
    "\n",
    "# from langchain_google_vertexai import VertexAIEmbeddings\n",
    "\n",
    "# import psycopg2\n",
    "# from pgvector.psycopg2 import register_vector\n",
    "\n",
    "# class CourseContentRetriever(BaseRetriever):\n",
    "#     \"\"\"Retriever to find relevant course content based on the\n",
    "#     query provided.\"\"\"\n",
    "\n",
    "#     embeddings_service: VertexAIEmbeddings    \n",
    "#     similarity_threshold: float\n",
    "#     num_matches: int\n",
    "#     conn_str: str\n",
    "\n",
    "#     def _get_relevant_documents(\n",
    "#             self, query: str, *, run_manager: CallbackManagerForRetrieverRun\n",
    "#         ) -> List[Document]:\n",
    "#         conn = psycopg2.connect(self.conn_str)\n",
    "#         register_vector(conn)\n",
    "\n",
    "#         qe = self.embeddings_service.embed_query(query)\n",
    "\n",
    "#         with conn.cursor() as cur:\n",
    "#             cur.execute(\n",
    "#                 \"\"\"\n",
    "#                         WITH vector_matches AS (\n",
    "#                         SELECT id, content, 1 - (embedding <=> %s::vector) AS similarity\n",
    "#                         FROM course_content_embeddings\n",
    "#                         WHERE 1 - (embedding <=> %s::vector) > %s\n",
    "#                         ORDER BY similarity DESC\n",
    "#                         LIMIT %s\n",
    "#                         )\n",
    "#                         SELECT cc.id as id, cc.title as title, \n",
    "#                             vm.content as content, \n",
    "#                             vm.similarity as similarity \n",
    "#                         FROM course_contents cc\n",
    "#                         LEFT JOIN vector_matches vm ON cc.id = vm.id;\n",
    "#                 \"\"\",\n",
    "#                 (qe, qe, self.similarity_threshold, self.num_matches)\n",
    "#             )\n",
    "#             results = cur.fetchall()\n",
    "\n",
    "#         conn.close()\n",
    "\n",
    "#         if not results:\n",
    "#             return []\n",
    "        \n",
    "#         return [\n",
    "#             Document(\n",
    "#                 page_content=r[2],\n",
    "#                 metadata={\n",
    "#                     \"id\": r[0],\n",
    "#                     \"title\": r[1],\n",
    "#                     \"similarity\": r[3],\n",
    "#                 }\n",
    "#             ) for r in results if r[2] is not None\n",
    "#         ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tool\n",
    "# def search_course_content(query: str) -> str:\n",
    "#     \"\"\"Explain about software security course materials.\"\"\"\n",
    "    \n",
    "#     retriever = CourseContentRetriever(embeddings_service=embeddings_service, \n",
    "#                                        conn_str=db_conn_string, \n",
    "#                                        similarity_threshold=0.1, \n",
    "#                                        num_matches=10)\n",
    "#     result = str(retriever.invoke(query))\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_course_content.invoke(\"best practices for forgot password\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CourseAPIClient:\n",
    "  def __init__(self, url=api_base_url):\n",
    "    self.url = url\n",
    "    \n",
    "  def list_courses(self):\n",
    "      response = requests.get(f\"{self.url}/courses\")\n",
    "      return response.json()\n",
    "\n",
    "  def get_course(self, course_name):\n",
    "      response = requests.get(f\"{self.url}/courses/{course_name}\")\n",
    "      return response.json()\n",
    "\n",
    "  def create_order(self, course, user_name, user_email):\n",
    "      payload = {\n",
    "          \"course\": course,\n",
    "          \"user_name\": user_name,\n",
    "          \"user_email\": user_email\n",
    "      }\n",
    "      response = requests.post(f\"{self.url}/orders\", json=payload)\n",
    "      return response.json()\n",
    "\n",
    "  def get_order(self, order_id):\n",
    "      response = requests.get(f\"{self.url}/orders/{order_id}\")\n",
    "      return response.json()\n",
    "\n",
    "  def pay_order(self, order_id):\n",
    "      response = requests.post(f\"{self.url}/orders/{order_id}:pay\")\n",
    "      return response.json()\n",
    "\n",
    "  def get_payment_page_url(self, order_id):\n",
    "      return f\"{self.url}/orders/{order_id}/payment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def list_courses() -> List[str]:\n",
    "  \"\"\"List all available courses sold on the platform.\"\"\"\n",
    "  client = CourseAPIClient()\n",
    "  return client.list_courses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetCourseInput(BaseModel):\n",
    "    course: str = Field(description=\"name of the course. this is the unique identifier of the course. it typically contains the course title with dashes, all in lowercase.\")\n",
    "\n",
    "@tool(\"get-course-tool\", args_schema=GetCourseInput)\n",
    "def get_course(course: str) -> str:\n",
    "  \"\"\"Get course details by course name. course name is the unique identifier of the course. it typically contains the course title with dashes.\n",
    "  This function can be used to get course details such as course price, etc.\"\"\"\n",
    "  client = CourseAPIClient()\n",
    "  return client.get_course(course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateOrderInput(BaseModel):\n",
    "    course: str = Field(description=\"name of the course. this is the unique identifier of the course. it typically contains the course title with dashes, all in lowercase.\")\n",
    "    user_name: str = Field(description=\"name of the user who is purchasing the course .\")\n",
    "    user_email: str = Field(description=\"email of the user who is purchasing the course.\")\n",
    "\n",
    "@tool(\"create-order-tool\", args_schema=CreateOrderInput)\n",
    "def create_order(course: str, user_name: str, user_email: str) -> str:\n",
    "  \"\"\"Create order for a course. This function can be used to create an order for a course. When this function returns successfully, it will return payment url to user to make payment. \"\"\"\n",
    "  client = CourseAPIClient()\n",
    "  \n",
    "  print(f\"Creating order for course: {course}, user_name: {user_name}, user_email: {user_email}\")\n",
    "  \n",
    "  res = client.create_order(course, user_name, user_email)\n",
    "  print(res)\n",
    "  order_id = res[\"order_id\"]\n",
    "  payment_url = f\"{api_base_url}/orders/{order_id}/payment\"\n",
    "  return f\"Order number {order_id} created successfully. Payment URL: {payment_url}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating order for course: software-security, user_name: John Doe, user_email: imre@gmail.com\n",
      "{'order_id': '31462f63-aeb9-4ebe-a1bf-bd1b4eb87d5a'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Order number 31462f63-aeb9-4ebe-a1bf-bd1b4eb87d5a created successfully. Payment URL: https://courses-api-uzttxm4diq-uc.a.run.app/orders/31462f63-aeb9-4ebe-a1bf-bd1b4eb87d5a/payment'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_order.invoke({\"course\":\"software-security\", \"user_name\":\"John Doe\", \"user_email\":\"imre@gmail.com\"}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetOrderInput(BaseModel):\n",
    "    order_number: str = Field(description=\"order number identifier. this is a unique identifier in uuid format.\")\n",
    "\n",
    "@tool(\"get-order-tool\", args_schema=GetOrderInput)\n",
    "def get_order(order_number: str) -> str:\n",
    "  \"\"\"Get order by using order number. This function can be used to get order details such as payment status to check whether the order has been paid or not. If user already paid the course, say thanks\"\"\"\n",
    "  client = CourseAPIClient()\n",
    "  return client.get_order(order_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools = [search_course_content, list_courses, get_course, create_order, get_order]\n",
    "tools = [list_courses, get_course, create_order, get_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = {\n",
    "    \"chat_history\": lambda x: x[\"history\"],\n",
    "    \"input\": lambda x: x[\"input\"],\n",
    "    \"agent_scratchpad\": (\n",
    "        lambda x: format_to_openai_function_messages(x[\"intermediate_steps\"])\n",
    "    ),\n",
    "} | ChatPromptTemplate(\n",
    "  messages = [\n",
    "    SystemMessagePromptTemplate.from_template(\"\"\"\n",
    "      You are a bot assistant that sells online course about software security. You only use information provided from datastore or tools. You can provide the information that is relevant to the user's question or the summary of the content. If they ask about the content, you can give them more detail about the content. If the user seems interested, you may suggest the user to enroll in the course. \n",
    "      \"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\n",
    "    HumanMessagePromptTemplate.from_template(\"Use tools to answer this questions: {input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model safety settings\n",
    "safety_settings = {\n",
    "    HarmCategory.HARM_CATEGORY_UNSPECIFIED: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "}\n",
    "\n",
    "## Model parameters\n",
    "model_kwargs = {\n",
    "    \"temperature\": 0.5,\n",
    "    \"safety_settings\": safety_settings,\n",
    "}\n",
    "\n",
    "agent = reasoning_engines.LangchainAgent(\n",
    "    model=gemini_llm_model,\n",
    "    tools=tools,\n",
    "    prompt=prompt,    \n",
    "    chat_history=get_session_history,\n",
    "    agent_executor_kwargs={\n",
    "      \"return_intermediate_steps\": True,\n",
    "    },\n",
    "    model_kwargs=model_kwargs,\n",
    "    enable_tracing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated session ID: 7fcb9a43-8b62-49c8-9000-83787b27dc73\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "# Generate a UUID for the session ID\n",
    "session_id = str(uuid.uuid4())\n",
    "print(f\"Generated session ID: {session_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This course will teach you about software security. You will learn how to secure your software and protect it from attacks. Are you interested in enrolling? \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = agent.query(\n",
    "  input=\"Can you please share what are being taught on this course?\",\n",
    "  config={\"configurable\": {\"session_id\": session_id}},\n",
    ")\n",
    "display(Markdown(response[\"output\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This course will teach you about how to secure your software and protect it from attacks. However, the course curriculum doesn't seem to cover designing a secure forgot password system. Would you like to explore other aspects of software security covered in this course? \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = agent.query(\n",
    "  input=\"Does it teach about how to design a forgot password system securely?\",\n",
    "  config={\"configurable\": {\"session_id\": session_id}},\n",
    ")\n",
    "display(Markdown(response[\"output\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This course costs $100. Do you want to enroll? \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = agent.query(\n",
    "  input=\"How much this course costs?\",\n",
    "  config={\"configurable\": {\"session_id\": session_id}},\n",
    ")\n",
    "display(Markdown(response[\"output\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "What is your name and email address? I need this information to enroll you in the course. \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = agent.query(\n",
    "  input=\"Yes. I want to enroll\",\n",
    "  config={\"configurable\": {\"session_id\": session_id}},\n",
    ")\n",
    "display(Markdown(response[\"output\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Span has more then 32 attributes, some will be truncated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating order for course: software-security, user_name: Mulyono, user_email: mulyono@gmail.com\n",
      "{'order_id': 'd03d182a-dc50-4336-be57-ffcde3d04737'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Span has more then 32 attributes, some will be truncated\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Order number d03d182a-dc50-4336-be57-ffcde3d04737 created successfully. Payment URL: https://courses-api-uzttxm4diq-uc.a.run.app/orders/d03d182a-dc50-4336-be57-ffcde3d04737/payment\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = agent.query(\n",
    "  input=\"Mulyono, mulyono@gmail.com\",\n",
    "  config={\"configurable\": {\"session_id\": session_id}},\n",
    ")\n",
    "display(Markdown(response[\"output\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Span has more then 32 attributes, some will be truncated\n",
      "Span has more then 32 attributes, some will be truncated\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Thank you for your payment! We will process your order and grant you access to the course materials shortly. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = agent.query(\n",
    "  input=\"I have made the payment. Can you please check?\",\n",
    "  config={\"configurable\": {\"session_id\": session_id}},\n",
    ")\n",
    "display(Markdown(response[\"output\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying the Agent on Vertex AI\n",
    "\n",
    "Deploying is as simple as calling `create()` method. We will provide the agent here and some dependencies required to run the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bucket courses-imrenagicom-agent\n",
      "Writing to gs://courses-imrenagicom-agent/reasoning_engine/reasoning_engine.pkl\n",
      "Writing to gs://courses-imrenagicom-agent/reasoning_engine/requirements.txt\n",
      "Creating in-memory tarfile of extra_packages\n",
      "Writing to gs://courses-imrenagicom-agent/reasoning_engine/dependencies.tar.gz\n",
      "Creating ReasoningEngine\n",
      "Create ReasoningEngine backing LRO: projects/896489987664/locations/us-central1/reasoningEngines/4869956901745459200/operations/7503369335683940352\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_OperationNotComplete\u001b[0m                     Traceback (most recent call last)",
      "File \u001b[0;32m~/projects/generative-ai/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n",
      "File \u001b[0;32m~/projects/generative-ai/.venv/lib/python3.11/site-packages/google/api_core/future/polling.py:120\u001b[0m, in \u001b[0;36mPollingFuture._done_or_raise\u001b[0;34m(self, retry)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone(retry\u001b[38;5;241m=\u001b[39mretry):\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _OperationNotComplete()\n",
      "\u001b[0;31m_OperationNotComplete\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 29\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# remote_agent = reasoning_engines.ReasoningEngine.create(\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#     agent,\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#     requirements=[\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#     )\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# remote_agent\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m remote_agent \u001b[38;5;241m=\u001b[39m \u001b[43mreasoning_engines\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReasoningEngine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgoogle-cloud-aiplatform[langchain,reasoningengine]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcloudpickle==3.0.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpydantic==2.7.4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrequests\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisplay_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcourse-agent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m remote_agent\n",
      "File \u001b[0;32m~/projects/generative-ai/.venv/lib/python3.11/site-packages/vertexai/reasoning_engines/_reasoning_engines.py:265\u001b[0m, in \u001b[0;36mReasoningEngine.create\u001b[0;34m(cls, reasoning_engine, requirements, reasoning_engine_name, display_name, description, gcs_dir_name, sys_version, extra_packages)\u001b[0m\n\u001b[1;32m    253\u001b[0m operation_future \u001b[38;5;241m=\u001b[39m sdk_resource\u001b[38;5;241m.\u001b[39mapi_client\u001b[38;5;241m.\u001b[39mcreate_reasoning_engine(\n\u001b[1;32m    254\u001b[0m     parent\u001b[38;5;241m=\u001b[39minitializer\u001b[38;5;241m.\u001b[39mglobal_config\u001b[38;5;241m.\u001b[39mcommon_location_path(\n\u001b[1;32m    255\u001b[0m         project\u001b[38;5;241m=\u001b[39msdk_resource\u001b[38;5;241m.\u001b[39mproject, location\u001b[38;5;241m=\u001b[39msdk_resource\u001b[38;5;241m.\u001b[39mlocation\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    262\u001b[0m     ),\n\u001b[1;32m    263\u001b[0m )\n\u001b[1;32m    264\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39mlog_create_with_lro(\u001b[38;5;28mcls\u001b[39m, operation_future)\n\u001b[0;32m--> 265\u001b[0m created_resource \u001b[38;5;241m=\u001b[39m \u001b[43moperation_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39mlog_create_complete(\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m    268\u001b[0m     created_resource,\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_resource_noun,\n\u001b[1;32m    270\u001b[0m     module_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertexai.preview.reasoning_engines\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    271\u001b[0m )\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# We use `._get_gca_resource(...)` instead of `created_resource` to\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;66;03m# fully instantiate the attributes of the reasoning engine.\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/generative-ai/.venv/lib/python3.11/site-packages/google/api_core/future/polling.py:256\u001b[0m, in \u001b[0;36mPollingFuture.result\u001b[0;34m(self, timeout, retry, polling)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_DEFAULT_VALUE, retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, polling\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    145\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the result of the operation.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m    This method will poll for operation status periodically, blocking if\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03m            the timeout is reached before the operation completes.\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_blocking_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolling\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;66;03m# pylint: disable=raising-bad-type\u001b[39;00m\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;66;03m# Pylint doesn't recognize that this is valid in this case.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n",
      "File \u001b[0;32m~/projects/generative-ai/.venv/lib/python3.11/site-packages/google/api_core/future/polling.py:137\u001b[0m, in \u001b[0;36mPollingFuture._blocking_poll\u001b[0;34m(self, timeout, retry, polling)\u001b[0m\n\u001b[1;32m    134\u001b[0m     polling \u001b[38;5;241m=\u001b[39m polling\u001b[38;5;241m.\u001b[39mwith_timeout(timeout)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[43mpolling\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_done_or_raise\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mRetryError:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mTimeoutError(\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOperation did not complete within the designated timeout of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpolling\u001b[38;5;241m.\u001b[39mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    142\u001b[0m     )\n",
      "File \u001b[0;32m~/projects/generative-ai/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/generative-ai/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:164\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m         _retry_error_helper(\n\u001b[1;32m    154\u001b[0m             exc,\n\u001b[1;32m    155\u001b[0m             deadline,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    161\u001b[0m             timeout,\n\u001b[1;32m    162\u001b[0m         )\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[0;32m--> 164\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(sleep)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSleep generator stopped yielding sleep values.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "remote_agent = reasoning_engines.ReasoningEngine.create(\n",
    "    agent,\n",
    "    requirements=[\n",
    "        \"google-cloud-aiplatform==1.69.0\",\n",
    "        \"google-cloud-aiplatform[langchain]\",\n",
    "        \"google-cloud-aiplatform[reasoningengine]\",\n",
    "        \"langchain==0.2.16\",\n",
    "        \"langchain_core==0.2.39\",\n",
    "        \"langchain_community==0.2.17\",\n",
    "        \"langchain-google-vertexai==1.0.10\",\n",
    "        \"cloudpickle==3.1.0\",\n",
    "        \"pydantic==2.9.2\",\n",
    "        \"langchain-google-community==1.0.8\",\n",
    "        \"google-cloud-discoveryengine==0.12.3\",\n",
    "        \"nest-asyncio\",\n",
    "        \"asyncio==3.4.3\",\n",
    "        \"asyncpg==0.29.0\",\n",
    "        \"cloud-sql-python-connector[asyncpg]==1.12.1\",        \n",
    "        \"langchain-google-cloud-sql-pg==0.11.0\",\n",
    "        \"numpy\",\n",
    "        \"pandas\",\n",
    "        \"pgvector==0.3.5\",\n",
    "        \"psycopg2-binary==2.9.9\",\n",
    "        \"requests\"\n",
    "    ],\n",
    "    display_name=\"course-agent\"\n",
    "    )\n",
    "remote_agent\n",
    "\n",
    "\n",
    "remote_agent\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grant Discovery Engine Editor access to Reasoning Engine service account\n",
    "\n",
    "Before you send queries to your remote agent, you'll need to grant the **Discovery Engine Editor** role to the Reasoning Engine service account.\n",
    "\n",
    "After you've completed this step, you remote agent will be able to retrieve documents from the data store that you created in Vertex AI Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the project number associated with your project ID\n",
    "from googleapiclient import discovery\n",
    "service = discovery.build(\"cloudresourcemanager\", \"v1\")\n",
    "request = service.projects().get(projectId=project_id)\n",
    "response = request.execute()\n",
    "project_number = response[\"projectNumber\"]\n",
    "project_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new role binding to the IAM policy\n",
    "!gcloud projects add-iam-policy-binding {project_id} \\\n",
    "    --member=serviceAccount:service-{project_number}@gcp-sa-aiplatform-re.iam.gserviceaccount.com \\\n",
    "    --role=roles/discoveryengine.editor\n",
    "\n",
    "!gcloud projects add-iam-policy-binding {project_id} \\\n",
    "    --member=serviceAccount:service-{project_number}@gcp-sa-aiplatform-re.iam.gserviceaccount.com \\\n",
    "    --role=\"roles/cloudsql.client\"\n",
    "\n",
    "!gcloud projects add-iam-policy-binding {project_id} \\\n",
    "    --member=serviceAccount:service-{project_number}@gcp-sa-aiplatform-re.iam.gserviceaccount.com \\\n",
    "    --role=\"roles/run.invoker\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test your remotely deployed agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing the remote agent\n",
    "# response = remote_agent.query(\n",
    "#   input=\"Imre and imre@gmail.com\",\n",
    "#   config={\"configurable\": {\"session_id\": \"test1235\"}},\n",
    "# )\n",
    "# display(Markdown(response[\"output\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Up\n",
    "\n",
    "Don't forget to clean up the resources after you are done with the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reasoning_engines.ReasoningEngine.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_agent = reasoning_engines.ReasoningEngine('projects/896489987664/locations/us-central1/reasoningEngines/6601028008515993600')\n",
    "\n",
    "# remote_agent.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some movies about engineers:\n",
      "\n",
      "* **Space Cowboys (2000)**: A retired engineer agrees to help NASA prevent a Russian satellite from falling to Earth.\n",
      "* **The Machinist (2004)**: A factory worker begins to question his sanity after a prolonged bout of insomnia.\n",
      "* **Back to Q82 (2019)**: An inventor's daughter drives his time-traveling car back to 1982.\n"
     ]
    }
   ],
   "source": [
    "print(remote_agent.query(input=\"movies about engineers\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
